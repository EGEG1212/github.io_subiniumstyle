---
title: "자연어 언어모델 ‘BERT’"
category:
  - category1
tag:
  - tag1
author_profile: true
sidebar_main: true
use_math: true

toc: true
---

![BERT는이렇게생겼습니다.](https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2F20120220_241%2F7ambivalenc_13296645616134lQzp_JPEG%2Fhow-to-draw-bert-and-ernie-tutorial-drawing.jpg&type=sc960_832)

# 자연어 언어모델 ‘BERT’

> 자연어 언어모델에 대해 관심이 생겼다. <br> 어릴때 봤었던 세서미스트리트의 친숙한 형아 버트... 역시나 똑똑한 친구

<br><br>

| **강좌정보** | [Tacademy강좌링크](https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=164)                                                  |
| :----------: | :------------------------------------------------------------------------------------------------------------------------------------------------ |
| **학습내용** | 1. 자연어의 개념과 다양한 언어모델에 대해 알아본다. <br>2. BERT 모델의 개념 및 메커니즘에 대해 이해하고, 한국어의 BERT 학습 방법에 대해 알아본다. |
|   **강사**   | 김성현 (솔트룩스)                                                                                                                                 |
| **학습기간** | 2021.01.14~2021.02.13 **이수완료**                                                                                                                |
| **학습시간** | 02:40:11                                                                                                                                          |
| **강의목록** | [1강] 자연어 처리(NLP)                                                                                                                            |
|              | [2강] 언어 모델(Language Model)                                                                                                                   |
|              | [3강] BERT                                                                                                                                        |
|              | [4강] 한국어BERT                                                                                                                                  |
|              | [5강] BERT실습                                                                                                                                    |
|  **GitHub**  | <https://github.com/EGEG1212/z_research/tree/main/NLP-Transfomer_BERT__Wikidosc_Tacademy>                                                         |
